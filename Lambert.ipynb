{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Implementation of online TSL learning algorithm as presented in [Lambert (2021)](https://proceedings.mlr.press/v153/lambert21a/lambert21a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, product\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsorted(collection, key = lambda x:x): \n",
    "\t'''\n",
    "\tThis method implements numerical sorting, rather than default lexicographical sorting of sorted()\n",
    "\t'''\n",
    "\tif collection.__class__ == dict:\n",
    "\t\treturn {key:collection[key] for key in nsorted(collection.keys())}\n",
    "\treturn sorted(collection, key = lambda element : (len(key(element)), key(element)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set:\n",
    "\t'''\n",
    "\tThis is just a wrapper class around python's set class, which allows Sets to be placed in other Sets\n",
    "\t'''\n",
    "\tdef __init__(self, _set = {}):\n",
    "\t\tself._set = set(_set)\n",
    "\t\tself._rehash()\n",
    "\n",
    "\tdef _rehash(self):\n",
    "\t\tself._hash = tuple(nsorted(self._set)).__hash__()\n",
    "\tdef __hash__(self):\n",
    "\t\tif self._hash is None:\n",
    "\t\t\tself._rehash()\n",
    "\t\treturn self._hash\n",
    "\n",
    "\tdef __eq__(self, other):\n",
    "\t\treturn self.__class__ == other.__class__ and self._set == other._set\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self._set)\n",
    "\tdef __repr__(self):\n",
    "\t\treturn '{{{0}}}'.format(', '.join(map(repr, nsorted(self._set))))\n",
    "\tdef __str__(self):\n",
    "\t\treturn self.__repr__()\n",
    "\tdef __lt__(self, other):\n",
    "\t\tif other.__class__ == self.__class__:\n",
    "\t\t\treturn self._set.__lt__(other._set)\n",
    "\t\treturn self._set.__lt__(other)\n",
    "\tdef __gt__(self, other):\n",
    "\t\tif other.__class__ == self.__class__:\n",
    "\t\t\treturn self._set.__gt__(other._set)\n",
    "\t\treturn self._set.__gt__(other)\n",
    "\tdef __leq__(self, other):\n",
    "\t\tif other.__class__ == self.__class__:\n",
    "\t\t\treturn self._set.__leq__(other._set)\n",
    "\t\treturn self._set.__leq__(other)\n",
    "\tdef __geq__(self, other):\n",
    "\t\tif other.__class__ == self.__class__:\n",
    "\t\t\treturn self._set.__geq__(other._set)\n",
    "\t\treturn self._set.__geq__(other)\n",
    "\tdef __iter__(self):\n",
    "\t\treturn self._set.__iter__()\n",
    "\tdef issubset(self, other):\n",
    "\t\treturn self._set.issubset(other._set)\n",
    "\tdef issuperset(self, other):\n",
    "\t\treturn self._set.issuperset(other._set)\n",
    "\tdef union(self, other):\n",
    "\t\treturn Set((self._set.union(other._set)))\n",
    "\n",
    "\tdef add(self, e):\n",
    "\t\tself._set.add(e)\n",
    "\t\tself._hash = None; self._ordered = False\n",
    "\tdef update(self, es):\n",
    "\t\tself._set.update(es)\n",
    "\t\tself._hash = None; self._ordered = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictUnion(a, b):\n",
    "\t'''\n",
    "\tfor sets of augmented subsequences encoded as a dict from tuples of symbols to Sets of Sets, this function unions the two sets\n",
    "\t'''\n",
    "\tans = dict()\n",
    "\tfor e in a:\n",
    "\t\tans[e] = Set()\n",
    "\tfor e in b:\n",
    "\t\tans[e] = Set()\n",
    "\t\n",
    "\tfor e in a:\n",
    "\t\tans[e].update(a[e])\n",
    "\tfor e in b:\n",
    "\t\tans[e].update(b[e])\n",
    "\treturn ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def width_j_substrings(w, j):\n",
    "    return tuple(w[i:i+j] for i in range(len(w)-j+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the standard symbol and dependency widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2 # dependency width\n",
    "M = 2 # symbol width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner definitions/prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"$ f : \\Sigma^* \\rightarrow \\mathcal{P} \\left( \\Sigma^{\\leq k+1} \\right) $\n",
    "gathers all and only those substrings of $w$ whose width is bounded above by $ k+1 $\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w, k=K):\n",
    "    return Set  (\n",
    "                    sum (\n",
    "                            tuple(width_j_substrings(w, j) for j in range(k+1+1)), #get every j-factor for every value of j up to k+1 inclusive\n",
    "                            ()\n",
    "                        )\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"$ x : \\Sigma^* \\rightarrow \\mathcal{P} \\left( \\Sigma^{\\leq k} \\times \\mathcal{P} \\left( \\Sigma \\right) \\right) $ extracts the valid augmented subsequences of width bounded above by $k$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(w, k=K):\n",
    "\n",
    "    symbols_at_indices = lambda indices : tuple(w[index] for index in indices)\n",
    "    \n",
    "\n",
    "    augmented_subsequences = dict()         # Create a dictionary from subsequences to the set of their intervener sets\n",
    "    augmented_subsequences[()] = Set([Set()]) # The only set of symbols that can intervene a length-0 tuple is the empty set\n",
    "\n",
    "    for j in range(1, k+1):                                                             # iterate across factor lengths j, 1 to k inclusive\n",
    "        for subsequence_indices in list(combinations(range(len(w)), j)):                # look at each length-j subsequence of indices\n",
    "            subsequence = symbols_at_indices(subsequence_indices)               # extract the tuple of symbols at those selected indices\n",
    "            intervening_indices =   [                                                   # compute the intervening indices\n",
    "                                        intervening_index\n",
    "                                        for intervening_index in range(subsequence_indices[0], subsequence_indices[-1])\n",
    "                                        if intervening_index not in subsequence_indices\n",
    "                                    ]\n",
    "            intervening_set = Set(symbols_at_indices(intervening_indices))         # extract the set of symbols at the intervening indices\n",
    "\n",
    "            if set(subsequence).isdisjoint(set(intervening_set)):           # if there are no symbols shared by the subsequence and the interveners, this is a valid augmented subsequence\n",
    "                if subsequence not in augmented_subsequences:\n",
    "                    augmented_subsequences[subsequence] = Set()\n",
    "                augmented_subsequences[subsequence].add(intervening_set)    # add the set of augmented subsequences\n",
    "\n",
    "    return nsorted(augmented_subsequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"$ r :  \\mathcal{P} \\left( \\Sigma^{\\leq k} \\times \\mathcal{P} \\left( \\Sigma \\right) \\right) \\rightarrow \\mathcal{P} \\left( \\Sigma^{\\leq k} \\times \\mathcal{P} \\left( \\Sigma \\right) \\right)$ restricts the set of augmented subsequences to exclude any that are entailed by any other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(augmented_subsequences):\n",
    "    return  nsorted (\n",
    "                        {\n",
    "                            subsequence_symbols: Set((\n",
    "                                                        intervener_symbol_set\n",
    "                                                        for intervener_symbol_set in intervener_symbol_sets\n",
    "                                                        if  not any  (\n",
    "                                                                            intervener_symbol_set.issuperset(other_intervener_symbol_set)\n",
    "                                                                        and\n",
    "                                                                            intervener_symbol_set != other_intervener_symbol_set\n",
    "                                                                        for other_intervener_symbol_set in intervener_symbol_sets\n",
    "                                                                    )\n",
    "\n",
    "                                                    ))\n",
    "                            for subsequence_symbols, intervener_symbol_sets in augmented_subsequences.items()\n",
    "                        }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We can define a learner $ \\varphi \\left( \\langle  G_{\\ell}, G_s\\rangle, w \\right) = \\langle G_{\\ell} \\cup f \\left( w \\right), r \\left( G_s \\cup x \\left( w \\right) \\right) \\rangle$\" This is `learn_step`\n",
    "\n",
    "\"The composite grammar can immediately be used as an acceptor without further processing . . . \n",
    "$ \\mathcal{L} \\left( \\langle G_{\\ell}, G_s \\rangle \\right) = \\{ w : f \\left( w \\right) \\subseteq G_{\\ell} \\land r \\left( G_s \\cup x \\left( w \\right) \\right) \\subseteq G_s \\}$\n",
    ". In words, a string is accepted iff it has only permitted substrings and each of its valid augmented subsequences is attested or entailed by something that is attested.\" This is `scan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSL_Learner:\n",
    "    def __init__(self, k=K):\n",
    "        self.k = k          # dependency width\n",
    "        self.G_l = Set()    # substrings of length bounded above by k+1\n",
    "        self.G_s = dict()   # augmented subsequences of length bounded above by k\n",
    "    def __repr__(self):\n",
    "        return f'TSL-{self.k} Grammar\\n{self.G_l}\\n{self.G_s}'\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.scan(*args, **kwargs)\n",
    "\n",
    "    def preprocess(self, w):\n",
    "        return '>'*(self.k-1) + w + '<'*(self.k-1) # add word-boundary symbols\n",
    "\n",
    "    def scan(self, w_raw):\n",
    "        w = self.preprocess(w_raw)\n",
    "        return  (\n",
    "                        f(w, k = self.k).issubset(self.G_l)\n",
    "                    and\n",
    "                        all (\n",
    "                                (\n",
    "                                        subsequence in self.G_s.keys()\n",
    "                                    and\n",
    "                                        intervening_sets.issubset(self.G_s[subsequence])\n",
    "                                )\n",
    "                                for subsequence, intervening_sets in r(dictUnion(self.G_s, x(w, self.k))).items()\n",
    "                            )\n",
    "                )\n",
    "    \n",
    "    def learn_step(self, w_raw):\n",
    "        w = self.preprocess(w_raw)\n",
    "        self.G_l = self.G_l.union(f(w, k=self.k))\n",
    "        self.G_s = r(dictUnion(self.G_s, x(w, self.k)))\n",
    "    \n",
    "    def learn(self, W):\n",
    "        for w in tqdm(W):\n",
    "            self.learn_step(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITSL_Learner(TSL_Learner):\n",
    "    def __init__(self, k=K, m=M):\n",
    "        super().__init__(k)\n",
    "        self.m = m             # symbol width\n",
    "    def __repr__(self):\n",
    "        return f'ITSL-({self.k}, {self.m}) Grammar\\n{self.G_l}\\n{self.G_s}'\n",
    "\n",
    "    def preprocess(self, w):\n",
    "        return width_j_substrings( #break string into width-m symbols, i.e. symbols created from \n",
    "            '>'*(self.k*self.m-1) + w + '<'*(self.k*self.m-1), # add word-boundary symbols. Adding k*m-1 ensures that the first k-factor of consecutive m-width symbols contains exactly one true symbol, analogous to adding k-1 word boundary symbols for a TSL learner    \n",
    "            self.m\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
